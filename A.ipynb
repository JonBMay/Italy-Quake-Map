{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Input file handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all Epicentres / remove unuseful data / combine into single csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read epicenters from single CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./Epicenter/CPTI15_v2.0.xlsx',sheet_name='catalogue',encoding='latin1')\n",
    "\n",
    "## Remove NaN, duplicated events\n",
    "df.dropna(subset=['LatDef','LonDef'],inplace=True)\n",
    "df = df.drop_duplicates(subset=['Year','Mo','Da','Ho','Mi','Se','LatDef','LonDef'], keep='first')\n",
    "\n",
    "## Create dataframe with only Lat & Lon & Mw\n",
    "df_LL = df[['LatDef']+['LonDef']+['MwDef']]\n",
    "df_LL.columns = ['Lat', 'Lon', 'Mw']\n",
    "\n",
    "## Save to single csv file\n",
    "df_LL.to_csv('A_single.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read epicenters from multiple CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "df = pd.concat([pd.read_csv(f,encoding='latin1') for f in glob.glob('./Epicenter/*.csv')],ignore_index = True)\n",
    "\n",
    "## Remove NaN, duplicated events\n",
    "df.dropna(subset=['Lat','Lon'],inplace=True) # *.csv\n",
    "df = df.drop_duplicates(subset=['Year Mo Da Ho Mi Se','LatDef','LonDef'], keep='first')\n",
    "\n",
    "## Create dataframe with only Lat & Lon & Mw\n",
    "df_LL = df[['Lat']+['Lon']+['Mw']]\n",
    "\n",
    "## Save to single csv file\n",
    "df_LL.to_csv('A_multiple.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Lat Lon points to geojson data / store inside new csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Epicenter input & Filter by magnitude\n",
    "df_LL = pd.read_csv('A_single.csv')\n",
    "df_LL = df_LL[(df_LL['Mw'] >= 5) & (df_LL['Mw'] <= 7)] # Magnitude filter better early to reduce work later\n",
    "\n",
    "## GeoJson file\n",
    "json_dir='geojson-italy-master/geojson'\n",
    "json_file='IT_regions.json'\n",
    "## Output file\n",
    "output_dir='.'\n",
    "output_file='region.csv'\n",
    "\n",
    "JsonFile=json_dir+'/'+json_file\n",
    "OutFile=output_dir+'/'+output_file\n",
    "\n",
    "## Initialise dataframe\n",
    "df_data = pd.DataFrame(index=range(df_LL.shape[0]),columns=['Lat','Lon','Mw','reg_name','reg_istat'])\n",
    "df_data = df_data.astype({'Lat':float,'Lon':float,'Mw':float,'reg_name':str,'reg_istat':str})\n",
    "\n",
    "## Populate df_data\n",
    "region = gpd.read_file(JsonFile)\n",
    "for i in range(df_LL.shape[0]):\n",
    "    point=Point(df_LL.iloc[i,1],df_LL.iloc[i,0])\n",
    "    for poly,reg,Ristat in zip(region['geometry'],region['reg_name'],region['reg_istat_code_num']):\n",
    "        if shape(poly).contains(point):\n",
    "            df_data.loc[i]=pd.Series({'Lat':df_LL.iloc[i,0],'Lon':df_LL.iloc[i,1],'Mw':df_LL.iloc[i,2],'reg_name':reg,'reg_istat':Ristat})\n",
    "            break\n",
    "            \n",
    "## Clean & Sort\n",
    "df_data.dropna(subset=['Lat','Lon'],inplace=True) # Incase epicentre has no assigned geojson area (Sea)\n",
    "df_data.sort_values(by=['reg_name'],inplace=True)\n",
    "\n",
    "## Filter by region(s)\n",
    "#df_data = df_data[(df_data['reg_name'] == 'Abruzzo')] # Single region\n",
    "#df_data = df_data[(df_data['reg_name'] == 'Abruzzo') | (df_data['reg_name'] == 'Calabria')] # Multiple regions\n",
    "\n",
    "## Format & Write to CSV file\n",
    "df_data['Lat'] = df_data['Lat'].map(lambda x: '%2.3f' % x)\n",
    "df_data['Lon'] = df_data['Lon'].map(lambda x: '%2.3f' % x)\n",
    "df_data.to_csv(OutFile,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provincial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Epicenter input & Filter by magnitude\n",
    "df_LL = pd.read_csv('A_single.csv')\n",
    "df_LL = df_LL[(df_LL['Mw'] >= 5) & (df_LL['Mw'] <= 7)] # Magnitude filter better early to reduce work later\n",
    "\n",
    "## GeoJson file\n",
    "json_dir='geojson-italy-master/geojson'\n",
    "json_file='IT_provinces.json'\n",
    "## Output file\n",
    "output_dir='.'\n",
    "output_file='province.csv'\n",
    "\n",
    "JsonFile=json_dir+'/'+json_file\n",
    "OutFile=output_dir+'/'+output_file\n",
    "\n",
    "## Initialise combined dataframe\n",
    "df_data = pd.DataFrame(index=range(df_LL.shape[0]),columns=['Lat','Lon','Mw','reg_name','reg_istat','prov_name','prov_istat'])\n",
    "df_data = df_data.astype({'Lat':float,'Lon':float,'Mw':float,'reg_name':str,'reg_istat':str,'prov_name':str,'prov_istat':str})\n",
    "\n",
    "## Populate df_data\n",
    "province = gpd.read_file(JsonFile)\n",
    "for i in range(df_LL.shape[0]):\n",
    "    point=Point(df_LL.iloc[i,1],df_LL.iloc[i,0])\n",
    "    for poly,reg,Ristat,prov,Pistat in zip(province['geometry'],province['reg_name'],province['reg_istat_code_num'],province['prov_name'],province['prov_istat_code_num']):\n",
    "        if shape(poly).contains(point):\n",
    "            df_data.loc[i]=pd.Series({'Lat':df_LL.iloc[i,0],'Lon':df_LL.iloc[i,1],'Mw':df_LL.iloc[i,2],'reg_name':reg,'reg_istat':Ristat,'prov_name':prov,'prov_istat':Pistat})\n",
    "            break\n",
    "\n",
    "## Clean & Sort\n",
    "df_data.dropna(subset=['Lat','Lon'],inplace=True) # Incase epicentre has no assigned geojson area (Sea)\n",
    "df_data.sort_values(by=['reg_name','prov_name'],inplace=True)\n",
    "\n",
    "## Filter by region(s) / province(s)\n",
    "#df_data = df_data[(df_data['reg_name'] == 'Abruzzo')] # Single region\n",
    "#df_data = df_data[(df_data['reg_name'] == 'Abruzzo') | (df_data['reg_name'] == 'Calabria')] # Multiple regions\n",
    "#df_data = df_data[(df_data['prov_name'] == 'Benevento')] # Single province\n",
    "#df_data = df_data[(df_data['prov_name'] == 'Benevento') | (df_data['prov_name'] == \"L'Aquila\")] # Multiple provinces\n",
    "\n",
    "## Format & Write to CSV file\n",
    "df_data['Lat'] = df_data['Lat'].map(lambda x: '%2.3f' % x)\n",
    "df_data['Lon'] = df_data['Lon'].map(lambda x: '%2.3f' % x)\n",
    "df_data.to_csv(OutFile,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Municipal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Epicenter input & Filter by magnitude\n",
    "df_LL = pd.read_csv('A_single.csv')\n",
    "df_LL = df_LL[(df_LL['Mw'] >= 5) & (df_LL['Mw'] <= 7)] # Magnitude filter better early to reduce work later\n",
    "\n",
    "## GeoJson file\n",
    "json_dir='geojson-italy-master/geojson'\n",
    "json_file='IT_municipalities.json'\n",
    "## Output file\n",
    "output_dir='.'\n",
    "output_file='municipality.csv'\n",
    "\n",
    "JsonFile=json_dir+'/'+json_file\n",
    "OutFile=output_dir+'/'+output_file\n",
    "\n",
    "## Initialise combined dataframe\n",
    "df_data = pd.DataFrame(index=range(df_LL.shape[0]),columns=['Lat','Lon','Mw','reg_name','reg_istat','prov_name','prov_istat','munic_name'])\n",
    "df_data = df_data.astype({'Lat':float,'Lon':float,'Mw':float,'reg_name':str,'reg_istat':str,'prov_name':str,'prov_istat':str,'munic_name':str})\n",
    "\n",
    "## Populate df_data\n",
    "municipality = gpd.read_file(JsonFile)\n",
    "for i in range(df_LL.shape[0]):\n",
    "    point=Point(df_LL.iloc[i,1],df_LL.iloc[i,0])\n",
    "    for poly,reg,Ristat,prov,Pistat,munic in zip(municipality['geometry'],municipality['reg_name'],municipality['reg_istat_code_num'],municipality['prov_name'],municipality['prov_istat_code_num'],municipality['name']):\n",
    "        if shape(poly).contains(point):\n",
    "            df_data.loc[i]=pd.Series({'Lat':df_LL.iloc[i,0],'Lon':df_LL.iloc[i,1],'Mw':df_LL.iloc[i,2],'reg_name':reg,'reg_istat':Ristat,'prov_name':prov,'prov_istat':Pistat,'munic_name':munic})\n",
    "            break\n",
    "\n",
    "## Clean & Sort\n",
    "df_data.dropna(subset=['Lat','Lon'],inplace=True) # Incase epicentre has no assigned geojson area (Sea)\n",
    "df_data.sort_values(by=['reg_name','prov_name','munic_name'],inplace=True)\n",
    "\n",
    "## Filter by region(s) / province(s) / municipality(s)\n",
    "#df_data = df_data[(df_data['reg_name'] == 'Abruzzo')] # Single region\n",
    "#df_data = df_data[(df_data['reg_name'] == 'Abruzzo') | (df_data['reg_name'] == 'Calabria')] # Multiple regions\n",
    "#df_data = df_data[(df_data['prov_name'] == 'Benevento')] # Single province\n",
    "#df_data = df_data[(df_data['prov_name'] == 'Benevento') | (df_data['prov_name'] == \"L'Aquila\")] # Multiple provinces\n",
    "#df_data = df_data[(df_data['munic_name'] == 'Celano')] # Single municipalty\n",
    "#df_data = df_data[(df_data['munic_name'] == 'Celano') | (df_data['munic_name'] == 'Sortino')] # Multiple municipalities\n",
    "\n",
    "## Format & Write to CSV file\n",
    "df_data['Lat'] = df_data['Lat'].map(lambda x: '%2.3f' % x)\n",
    "df_data['Lon'] = df_data['Lon'].map(lambda x: '%2.3f' % x)\n",
    "df_data.to_csv('municipality.csv',index=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
